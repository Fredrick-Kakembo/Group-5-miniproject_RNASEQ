---
title: "Differential Expression Analysis Script for all the Outputs"
author: "Fredrick E. Kakembo  & Ruth Nanjala"
date: "8/13/2020"
output:
  pdf_document: default
  html_document: default
---

```{r}
setwd("~/Desktop/EANBiT_Documents/RT_2020_Program/RNASeq_miniproject/Counts/")

#Loading the neccessary packages
library(DESeq2)

library(GenomicFeatures)
library("tximport")
library("readr")
```

# Part 1: Importing data

## 1. Importing Output from hisat's FeatureCount
```{r}
# HISAT

#Reading the metadata file
meta <- read.csv("practice.dataset.metadata.tsv", sep="\t", row.names = 1, header = T)
meta$Condition <- as.factor(meta$Condition)
meta

countdata <- read.csv("Hisat_featurecounts/hisat_counts.txt", sep="\t", header=T, row.names=1, comment.char = "#")
head(countdata)

#Check the columns
colnames(countdata)

#Remove the unwanted columns
countdata[c("Chr", "Start", "End", "Strand", "Length")] <- NULL

#Renaming the Colnames (to remove the suffix "_hisat_sorted.bam")
colnames(countdata) <- gsub("_hisat_sorted.bam", "", colnames(countdata))
head(countdata)

#Check if samples in the countdata matrix have a corresponding anotation in the metadata file
all(rownames(meta) %in% colnames(countdata))

#Check if the order of the samples in the matrix is similar to that in the metadata file.
all(colnames(countdata) == rownames(meta))

#Importing the data into DESeqDataSet Object
dds <- DESeqDataSetFromMatrix(countData = countdata,
                              colData = meta,
                              design = ~ Condition)
dds
```


## 2. Importing Output from Star's FeatureCounts
```{r}
#STAR

#Reading the STAR count matrix
star_count <- read.csv("Featurecounts/STAR_counts.txt", sep = "\t", header = T, row.names = 1, comment.char = "#")
head(star_count)

#Check column names
colnames(star_count)

#Remove the unwanted columns
star_count[c("Chr", "Start", "End", "Strand", "Length")] <- NULL

#Renaming the Colnames (to remove the prefix "STAR_Alignment." and suffix "_sorted.bam")
colnames(star_count) <- gsub("STAR_Alignment.", "", colnames(star_count))
colnames(star_count) <- gsub("_sorted.bam", "", colnames(star_count))
head(star_count)

#Importing the data into DESeqDataSet Object
star_dds <- DESeqDataSetFromMatrix(countData = star_count,
                              colData = meta,
                              design = ~ Condition)
star_dds
```


## 3. Importing Output from Kallisto
```{r}
# Kallisto

#read in a table that links transcripts to genes for this dataset. 
#We use the GenomicFeatures for this to create the tx2gene

# We create the TxDb obeject from the transcript annotation in the gff3 file
txdb <- makeTxDbFromGFF("gencode.v34.annotation.gff3")
txdb
gene_id <- keys(txdb, keytype = "GENEID")  #Extracct the GeneIDs
#Matching the transcripts with the geneIDs
tx2gene <- select(txdb, keys = gene_id, keytype = "GENEID", columns = "TXNAME")
head(tx2gene,10)


#Dircetory for Kallisto counts
kal_dir <- "/Users/kakembo/Desktop/EANBiT_Documents/RT_2020_Program/RNASeq_miniproject/Counts/Kallisto"
files <- file.path(kal_dir, rownames(meta),"abundance.h5" )
names(files) <- rownames(meta)
files

library("tximport")
library("readr")
#Reading the files for the different files
txi <- tximport(files, type="kallisto",tx2gene = tx2gene, txOut = T)

names(txi)

#Construct the  DESeqDataSet object
kallisto_dds <- DESeqDataSetFromTximport(txi,
                                   colData = meta,
                                   design = ~ Condition)
kallisto_dds
```



## 4. Import Output from Salmon
```{r}
#Dircetory for Salmon counts
sal_dir <- "/Users/kakembo/Desktop/EANBiT_Documents/RT_2020_Program/RNASeq_miniproject/Counts/Salmon"
list.files(sal_dir)
files <- file.path(sal_dir, paste(rownames(meta),"_quant", sep = ""), "quant.sf" )
names(files) <- rownames(meta)
files

txi <- tximport(files, type="salmon",tx2gene = tx2gene, txOut = T)
head(txi$abundance)

#Construct the  DESeqDataSet object
salmon_dds <- DESeqDataSetFromTximport(txi,
                                   colData = meta,
                                   design = ~ Condition)
salmon_dds
```



# Differential expression analysis

```{r}
#Transforming the counts & Calculating pvalue using DESeq function
#The steps it performs are the estimation of size factors (which control for differences in the library size of the sequencing experiments), the estimation of dispersion for each gene, and fitting a generalized linear model.
dds <- DESeq(dds)

#Extracting the reults form the formed dds object
res <- results(dds)

#Alternative ways;
#res <- results(dds, name="Condition_normal_vs_disease")
#res <- results(dds, contrast=c("Condition","normal","disease"))

res

# Log fold change shrinkage for visualization and ranking
## useful for visualization and ranking of genes. We shall use the apeglm method
resultsNames(dds)
resLFC <- lfcShrink(dds, coef="Condition_normal_vs_disease", type="apeglm")
resLFC

## p-values and adjusted p-values
#Reorder res based on pvalues
resOrdered <- res[order(res$pvalue),]
resOrdered

summary(res)

#Interpreting the LFC, since its normal vs disease, if the LFC > 0 means activity of the gene is lower in disease (downregulated), and if LFC < 0, means activity is higher in disease than in normal (upregulated).

#How many adjusted p-values were less than 0.1?
sum(res$padj < 0.1, na.rm=TRUE)

#By default cutoff alpha for padj is 0.1, however this can be changed so to 0.05 as shown below;
res05 <- results(dds, alpha=0.05)
summary(res05)

#The number of significant genes here decrease since 95% is much more stringient
sum(res05$padj < 0.05, na.rm=TRUE)

```

## Exploring and exporting results
```{r}
#MA-plot
#MA plot: The plot visualizes the differences between measurements taken in two samples, by transforming the data onto M and A scales, then plotting these values.
plotMA(res, ylim=c(-2,2))

#It is more useful visualize the MA-plot for the shrunken log2 fold changes, which remove the noise associated with log2 fold changes from low count genes without requiring arbitrary filtering thresholds.
plotMA(resLFC, ylim=c(-2,2))

#Alternative shrinkage estimators apart from apeglm
# because we are interested in treated vs untreated, we set 'coef=2'
resNorm <- lfcShrink(dds, coef=2, type="normal")
resAsh <- lfcShrink(dds, coef=2, type="ashr")

par(mfrow=c(1,3), mar=c(4,4,2,1))  #mar sets the margin sizes in the following order: bottom, left, top, and right.
xlim <- c(1,1e5); ylim <- c(-3,3)
plotMA(resLFC, xlim=xlim, ylim=ylim, main="apeglm")
plotMA(resNorm, xlim=xlim, ylim=ylim, main="normal")
plotMA(resAsh, xlim=xlim, ylim=ylim, main="ashr")
```

## Plot counts
```{r}
#This plots the normalized counts for each sample in the particular gene

#For the gene with the minimum padj
plotCounts(dds, gene=which.min(res$padj), intgroup="Condition")

#Or we could return a dataframe and plot it with ggplot2, we use the returnData=TRUE
d <- plotCounts(dds, gene=which.min(res$padj), intgroup="Condition", 
                returnData=TRUE)
d
#library("ggplot2")
#ggplot(d, aes(x=Condition, y=Count)) + 
#  geom_point(position=position_jitter(w=0.1,h=0)) + 
#  scale_y_log10(breaks=c(25,100,400))



#Look at the 6 genes with the lowest adj
head(resOrdered)


#Plot counts for these genes
par(mfrow=c(2,3))
plotCounts(dds, gene="ENSG00000039537", intgroup="Condition")
plotCounts(dds, gene="ENSG00000124237", intgroup="Condition")
plotCounts(dds, gene="ENSG00000160401", intgroup="Condition")
plotCounts(dds, gene="ENSG00000007908", intgroup="Condition")
plotCounts(dds, gene="ENSG00000188817", intgroup="Condition")
plotCounts(dds, gene="ENSG00000168658", intgroup="Condition")

#Compare this with non-significant p-values
tail(na.omit(resOrdered))

par(mfrow=c(2,3))
plotCounts(dds, gene="ENSG00000048991", intgroup="Condition")
plotCounts(dds, gene="ENSG00000236204", intgroup="Condition")
plotCounts(dds, gene="ENSG00000119403", intgroup="Condition")
plotCounts(dds, gene="ENSG00000198416", intgroup="Condition")
plotCounts(dds, gene="ENSG00000157625", intgroup="Condition")
plotCounts(dds, gene="ENSG00000107679", intgroup="Condition")
```

## A closer look at the columns for the result, res
```{r}
head(res)

#Notes
# - if basemean for all samples is zero, the p values and lfc will be NA
# - If a row contains any sample with extreme count outlier, the p-value and padj are set to NA
# - If a row is filetered due to low counts then only the padj is set to NA
```

```{r}
#Only subsettting genes with Significant padj value
resSig <- subset(resOrdered, padj < 0.1)
resSig

getwd()
```


## Exporting Significant Results
```{r}
resSig <- subset(resOrdered, padj < 0.1)
head(resSig)
write.table(as.data.frame(resSig),
          file="condition_treated_significant_results.csv")



```

## Data Transformation
Testing for DE operates on raw counts, however for visualizations and clusterings, its better to work with transformed count data. There are 2 common waays of transformation; which produce transformed data on the log2 scale which has been normalized with respect to library size or other normalization factors.

- Variance Stabilizing Transformations (VST)     and
- regularized logarithm or rlog

The goal of transformation is to eliminate any variance arising when the mean is low. rlog might be slower for many samples compared to vst.

One common argument used during transformation is `blind` which tells whether transformation should be blind to sample information specified in the the design (ie in an unbiased manner), hence using only the intercept. However this is not the best choice especially if the counts difference are attributed to the design and if one is to use the transformed data for downstream analysis. If `blind = FALSE` is set, we take into account already estimated dispersion due to design as we are transforming the data, and make the process much faster.

**Comparison:** 
VST runs faster than rlog. If the library size of the samples and therefore their size factors vary widely, the rlog transformation is a better option than VST. Both options produce log2 scale data which has been normalized by the DESeq2 method with respect to library size.

```{r}
#Count Transformations
vsd <- vst(dds, blind=FALSE)
rld <- rlog(dds, blind=FALSE)
head(assay(vsd))   #Assay extracts a matrix of normalized counts
head(assay(rld))
head(res)
head(countdata)
```

### Effects of transformations on the variance
The figure below plots the standard deviation of the transformed data, across samples, against the mean, using the shifted logarithm transformation, the regularized log transformation and the variance stabilizing transformation. 

**What we expect is:** The shifted logarithm has elevated standard deviation in the lower count range, and the regularized log to a lesser extent, while for the variance stabilized data the standard deviation is roughly constant along the whole dynamic range.

```{r}
#BiocManager::install("vsn")
library("vsn")

#for the untransformed dds
ntd <- normTransform(dds)
meanSdPlot(assay(ntd))

#for vst
meanSdPlot(assay(vsd))

#For rlog
meanSdPlot(assay(rld), bins = 100)

```

From the above plots i don't see much of the difference.

## Data quality assessment by sample clustering and visualization

### Heatmap of the sample-to-sample distances
A heatmap of this distance matrix gives us an overview over similarities and dissimilarities between samples. 
```{r}
#Calculate sample-2-sample distances
sampleDists <- dist(t(assay(vsd)))

library("RColorBrewer")
library(pheatmap)
sampleDistMatrix <- as.matrix(sampleDists)  #Converting the dist object to matrix
rownames(sampleDistMatrix) <- vsd$Condition 
colnames(sampleDistMatrix) <- rownames(meta)  #My modification to match samples and Condition
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
pheatmap(sampleDistMatrix,
         clustering_distance_rows=sampleDists,
         clustering_distance_cols=sampleDists,
         col=colors)


```
From this sample37 looks to be slightly different to other sanples (even those in the same Condition)

## Principal component plot of the samples
This plot gives a visual of the overall relatedness between the samples in the different batches
```{r}
plotPCA(vsd, intgroup="Condition")

```

From this PCA plot, one sample seems to be off among the normal category, which i presume its the samnple37.

## Dispersion plot
This plot generally show how gene expression data differs across samples in the same treatment group. 

- The black dots are the dispersion estimates for each gene separately
- The red line is the fitted trend which shows the dispersion's dependence on the mean.
- The blue dots are genes that have been shrunk/fitted towards the red line.
- The outer blue circles with black dots inside are considered outliers and therefore not shrunk towards the fitted line
```{r}
plotDispEsts(dds, main="Dispersion plot for DESeq")
```



## Adding Gene names
source: http://www.sthda.com/english/wiki/rna-seq-differential-expression-work-flow-using-deseq2#running-the-deseq2-pipeline 

The goal here is to use the Ensembl gene names to get the gene symbol and entryID which can then be used later to locate it function in the reactome database.

```{r}
#BiocManager::install("org.Hs.eg.db")

library("org.Hs.eg.db")
columns(org.Hs.eg.db)    #list of all available key types


convertIDs <- function( ids, fromKey, toKey, db, ifMultiple=c( "putNA", "useFirst" ) ) {
   stopifnot( inherits( db, "AnnotationDb" ) )
   ifMultiple <- match.arg( ifMultiple )
   suppressWarnings( selRes <- AnnotationDbi::select( 
      db, keys=ids, keytype=fromKey, columns=c(fromKey,toKey) ) )
   if( ifMultiple == "putNA" ) {
      duplicatedIds <- selRes[ duplicated( selRes[,1] ), 1 ]   
      selRes <- selRes[ ! selRes[,1] %in% duplicatedIds, ] }
   return( selRes[ match( ids, selRes[,1] ), 2 ] )
}

res1 <- res  #making a backup
res$hgnc_symbol <- convertIDs( row.names(res), "ENSEMBL", "SYMBOL", org.Hs.eg.db )
res$entrezid <- convertIDs( row.names(res), "ENSEMBL", "ENTREZID", org.Hs.eg.db )
head(res, 20)
```

## Gene-set enrichment analysis
The goal of this is to examine whether the observed genes with a strong/significant up- or down-regulation have either something in common or have something to do with the biological process causing the condition.

```{r}
#BiocManager::install("reactome.db")
library("reactome.db" )

#resSig
#Extracting only genes that have corresponding data in reactome and padj value is not an NA
res2 <- res[ res$entrezid %in% keys( reactome.db, "ENTREZID" ) & !is.na( res$padj ) , ]
head(res2)

#Next we use select for AnnotationDbi to map entrez_id to Reactome_IDs
reactomeTable <- AnnotationDbi::select( reactome.db, 
   keys=as.character(res2$entrezid), keytype="ENTREZID", 
   columns=c("ENTREZID","REACTOMEID") )
head(reactomeTable, 10)
tail(reactomeTable)

#We then tell which genes are members of which Reactome Paths.
incm <- do.call( rbind, with(reactomeTable, tapply( 
  ENTREZID, factor(REACTOMEID), function(x) res2$entrezid %in% x ) ))
colnames(incm) <- res2$entrez
str(incm)

#We remove all rows corresponding to Reactome Paths with less than 20 or more than 80 assigned genes.
within <- function(x, lower, upper) (x>=lower & x<=upper)
incm <- incm[ within(rowSums(incm), lower=20, upper=80), ]

#We test whether the genes in a Reactome Path behave in a special way in our experiment,
testCategory <- function(reactomeID) {
  isMember <- incm[ reactomeID, ]
  data.frame( 
     reactomeID  = reactomeID,
     numGenes    = sum( isMember ),
     avgLFC      = mean( res2$log2FoldChange[isMember] ),
     sdLFC       = sd( res2$log2FoldChange[isMember] ),
     zValue      = mean( res2$log2FoldChange[isMember] ) /sd( res2$log2FoldChange[isMember] ),
     strength    = sum( res2$log2FoldChange[isMember] ) / sqrt(sum(isMember)),
     pvalue      = t.test( res2$log2FoldChange[ isMember ] )$p.value,
     reactomeName = reactomePATHID2NAME[[reactomeID]],
     stringsAsFactors = FALSE ) }

#We call the function for all Paths in our incidence matrix and collect the results in a data frame:
reactomeResult <- do.call( rbind, lapply( rownames(incm), testCategory ) )
head(reactomeResult)

#Now we perform Multiple Testing Adjustment again
reactomeResult$padjust <- p.adjust( reactomeResult$pvalue, "BH" )

#We obtain the reactomeID with significant p.adj  values in our comparison of normal vs disease
reactomeResultSignif <- reactomeResult[ reactomeResult$padjust < 0.05, ]

print(head( reactomeResultSignif[ order(-reactomeResultSignif$strength), ] ,20))

```



## Extra Deseq
source: https://gif.biotech.iastate.edu/rnaseq-analysis-walk-through

```{r}

#Alternative Sample Distance matrix
(mycols <- brewer.pal(8, "Dark2")[1:length(unique(meta$Condition))])
# Sample distance heatmap
sampleDists <- as.matrix(dist(t(assay(rld))))
library(gplots)
heatmap.2(as.matrix(sampleDists), key=F, trace="none",
col=colorpanel(100, "black", "white"),
ColSideColors=mycols[meta$Condition], RowSideColors=mycols[meta$Condition],
margin=c(10, 10), main="Sample Distance Matrix")


#PCA Analysis
rld_pca <- function (rld, intgroup = "Condition", ntop = 500, colors=NULL, legendpos="bottomleft", main="PCA Biplot", textcx=1, ...) {
require(genefilter)
require(calibrate)
require(RColorBrewer)
rv = rowVars(assay(rld))
select = order(rv, decreasing = TRUE)[seq_len(min(ntop, length(rv)))]
pca = prcomp(t(assay(rld)[select, ]))
fac = factor(apply(as.data.frame(colData(rld)[, intgroup, drop = FALSE]), 1, paste, collapse = " : "))
if (is.null(colors)) {
if (nlevels(fac) >= 3) {
colors = brewer.pal(nlevels(fac), "Paired")
} else {
colors = c("black", "red")
}
}
pc1var <- round(summary(pca)$importance[2,1]*100, digits=1)
pc2var <- round(summary(pca)$importance[2,2]*100, digits=1)
pc1lab <- paste0("PC1 (",as.character(pc1var),"%)")
pc2lab <- paste0("PC1 (",as.character(pc2var),"%)")
plot(PC2~PC1, data=as.data.frame(pca$x), bg=colors[fac], pch=21, xlab=pc1lab, ylab=pc2lab, main=main, ...)
with(as.data.frame(pca$x), textxy(PC1, PC2, labs=rownames(as.data.frame(pca$x)), cex=textcx))
legend(legendpos, legend=levels(fac), col=colors, pch=20)
# rldyplot(PC2 ~ PC1, groups = fac, data = as.data.frame(pca$rld),
# pch = 16, cerld = 2, aspect = "iso", col = colours, main = draw.key(key = list(rect = list(col = colours),
# terldt = list(levels(fac)), rep = FALSE)))
}
rld_pca(rld, colors=mycols, intgroup="Condition", xlim=c(-75, 35))



#Getting DE results
resdata <- merge(as.data.frame(res), as.data.frame(counts(dds, normalized=TRUE)), by="row.names", sort=FALSE)
names(resdata)[1] <- "Gene"
head(resdata)

#Examine plot for pvalue
hist(res$pvalue, breaks=50, col="grey")


## MA plot
## Could do with built-in DESeq2 function:
## DESeq2::plotMA(dds, ylim=c(-1,1), cex=1)
## I like mine better:
maplot <- function (res, thresh=0.05, labelsig=TRUE, textcx=1, ...) {
with(res, plot(baseMean, log2FoldChange, pch=20, cex=.5, log="x", ...))
with(subset(res, padj<thresh), points(baseMean, log2FoldChange, col="red", pch=20, cex=1.5))
if (labelsig) {
require(calibrate)
with(subset(res, padj<thresh), textxy(baseMean, log2FoldChange, labs=Gene, cex=textcx, col=2))
}
}
maplot(resdata, main="MA Plot")


# Volcano plot with "significant" genes labeled
volcanoplot <- function (res, lfcthresh=2, sigthresh=0.05, main="Volcano Plot", legendpos="bottomright", labelsig=TRUE, textcx=1, ...) {
with(res, plot(log2FoldChange, -log10(pvalue), pch=20, main=main, ...))
with(subset(res, padj<sigthresh ), points(log2FoldChange, -log10(pvalue), pch=20, col="red", ...))
with(subset(res, abs(log2FoldChange)>lfcthresh), points(log2FoldChange, -log10(pvalue), pch=20, col="orange", ...))
with(subset(res, padj<sigthresh & abs(log2FoldChange)>lfcthresh), points(log2FoldChange, -log10(pvalue), pch=20, col="green", ...))
if (labelsig) {
require(calibrate)
with(subset(res, padj<sigthresh & abs(log2FoldChange)>lfcthresh), textxy(log2FoldChange, -log10(pvalue), labs=Gene, cex=textcx, ...))
}
legend(legendpos, xjust=1, yjust=1, legend=c(paste("FDR<",sigthresh,sep=""), paste("|LogFC|>",lfcthresh,sep=""), "both"), pch=20, col=c("red","orange","green"))
}
volcanoplot(resdata, lfcthresh=1, sigthresh=0.05, textcx=.8, xlim=c(-2.3, 2))
```

.




# Working With Sleuth
Sleuth is a fast, lightweight tool that uses transcript abundance estimates output from pseudo-alignment algorithms that use bootstrap sampling, such as Sailfish, Salmon, and Kallisto, to perform differential expression analysis of gene isoforms.
```{r}
#devtools::install_github("pachterlab/sleuth")
library(sleuth)

#suppressMessages({
#  library("sleuth")
#})

#Dir where kallisto results are stored
kal_dir <- "/Users/kakembo/Desktop/EANBiT_Documents/RT_2020_Program/RNASeq_miniproject/Counts/Kallisto"
sample_id <- dir(file.path(kal_dir))  #This stores the directories in the kallisto workspace
sample_id  

#Specifying the path to the files
kal_dirs <- file.path(kal_dir, sample_id, "abundance.h5")
kal_dirs

#Appending sample names from meta to their paths
metadata <- read.table("practice.dataset.metadata.tsv", header = T)
metadata

s2c <- dplyr::mutate(metadata, path = kal_dirs)
print(s2c)

colnames(s2c)[1] <- "sample"  #Sleuth wants the sample names to be specifically as "sample"

#Creating the sleuth object
## Step 1: load the kallisto processed data into the object

#Here i had to rerun the kallisto output with bootstrap values specified ie adding    -b 100
so <- sleuth_prep(s2c, extra_bootstrap_summary = TRUE)

#Fiiting the full model
so <- sleuth_fit(so, ~Condition, 'full')

#To test for transcripts that are differential expressed between the conditions, sleuth performs a second fit to a “reduced” model that presumes abundances are equal in the two conditions. 
#The reduced model is fit
so <- sleuth_fit(so, ~1, 'reduced')

# Perform a Likelihood Ratio Test for the 2 tests, so as to nest reduced model into full model
so <- sleuth_lrt(so, 'reduced', 'full')

#Checking the fitted models using model()
models(so)

#Examing the results of the test 
sleuth_table <- sleuth_results(so, 'reduced:full', 'lrt', show_all = FALSE)
head(sleuth_table)

#Filtering only significant results
#sleuth_significant <- dplyr::filter(sleuth_table, qval <= 0.05)
sleuth_significant <- dplyr::filter(sleuth_table, qval <= 0.1)
#Top 20 significant genes with BH testing at q-value <= 0.1
head(sleuth_significant, 20)
```

```{r}
#Plots
plot_bootstrap(so, "ENST00000278756.7|ENSG00000084234.17|OTTHUMG00000165767.5|OTTHUMT00000386112.2|APLP2-202|APLP2|3687|protein_coding|", units = "est_counts", color_by = "Condition")

par(mfrow=c(2,3))
plot_bootstrap(so, sleuth_significant$target_id[1], units = "est_counts", color_by = "Condition")
plot_bootstrap(so, sleuth_significant$target_id[2], units = "est_counts", color_by = "Condition")
plot_bootstrap(so, sleuth_significant$target_id[3], units = "est_counts", color_by = "Condition")
plot_bootstrap(so, sleuth_significant$target_id[4], units = "est_counts", color_by = "Condition")
plot_bootstrap(so, sleuth_significant$target_id[5], units = "est_counts", color_by = "Condition")
plot_bootstrap(so, sleuth_significant$target_id[6], units = "est_counts", color_by = "Condition")

```



# Working with EdgeR
Source:  https://gif.biotech.iastate.edu/rnaseq-analysis-walk-through 
I will implement output from hisat

```{r}
#BiocManager::install("edgeR")
library(edgeR)

# import data
#Using previously imported data for Hisat 
datain <- countdata
head(datain)

# create DGE object of edgeR
dgList <- DGEList(counts=datain,group=factor(meta$Condition))

# filter data to retain genes that are represented at least 1 counts per million (cpm) in at least 2 samples
countsPerMillion <- cpm(dgList)   #Compute the counts per million
countCheck <- countsPerMillion > 1   #Check which has more than 1cpm
keep <- which(rowSums(countCheck) >= 2)  #Check if in a row atleast 2 samples have 1cpm
dgList <- dgList[keep,]  #Subset the dgList for only qualifying genes
dgList$samples$lib.size <- colSums(dgList$counts)

# normalization using TMM method
dgList <- calcNormFactors(dgList, method="TMM")

# data exploration
# Multi Dimension Scale, MDS plot
plotMDS(dgList, method="bcv", col=as.numeric(dgList$samples$group))

# Dispersion estimates
design.mat <- model.matrix(~ 0 + dgList$samples$group)
colnames(design.mat) <- levels(dgList$samples$group)
dgList <- estimateGLMCommonDisp(dgList,design.mat)
dgList <- estimateGLMTrendedDisp(dgList,design.mat, method="power")
dgList <- estimateGLMTagwiseDisp(dgList,design.mat)
plotBCV(dgList)

# Differentail expression analysis
fit <- glmFit(dgList, design.mat)  #fits genewise negative binomial glms
lrt <- glmLRT(fit, contrast=c(1,-1))  #conducts likelihood ratio tests for one or more coefficients in the linear model.
edgeR_results <- topTags(lrt, n=Inf)
 
# plot log2FC of genes and highlight the DE genes at p = 0.05
deGenes <- decideTestsDGE(lrt, p=0.05)
deGenes <- rownames(lrt)[as.logical(deGenes)]
plotSmear(lrt, de.tags=deGenes)

# plot log2FC of genes and highlight the DE genes at p = 0.1
deGenes01 <- decideTestsDGE(lrt, p=0.1)
deGenes01 <- rownames(lrt)[as.logical(deGenes01)]
plotSmear(lrt, de.tags=deGenes01)
```
.
.
.
.
.
